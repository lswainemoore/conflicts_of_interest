{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather tweets for current legislators\n",
    "### Big picture:\n",
    "For each Twitter ID we have (source: https://github.com/unitedstates/congress-legislators), can gather a good chunk of tweets, and save the json to flat files using code adapted from https://gist.github.com/yanofsky/5436496."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "from keys import twitter\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_relative_path = \"../data/lincoln/\"\n",
    "tweets_location = data_relative_path + \"congress_searched_tweets/\"\n",
    "# log_location = \"./logs/stream_congress_log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET THE USER IDS\n",
    "df = pd.read_csv(data_relative_path + \"current_social_media.csv\", dtype=str)\n",
    "user_ids = df.twitter_id\n",
    "good_user_ids = []\n",
    "blah = []\n",
    "for uid in user_ids:\n",
    "    try:\n",
    "        # THIS IS JUST SO WE IGNORE NANS VALUES\n",
    "        g = int(uid)\n",
    "        good_user_ids.append(uid)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data from a user's Twitter timeline\n",
    "#### The next two cells are very much adapted from https://gist.github.com/yanofsky/5436496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(twitter[\"consumer_key\"], twitter[\"consumer_secret\"])\n",
    "auth.set_access_token(twitter[\"access_token\"], twitter[\"access_token_secret\"])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_tweets(user_id):\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(user_id = user_id,count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    # some users haven't tweeted ever!\n",
    "    if len(alltweets) != 0:\n",
    "    \n",
    "        #save the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        #keep grabbing tweets until there are no tweets left to grab\n",
    "        while len(new_tweets) > 0:\n",
    "            print (\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "            #all subsiquent requests use the max_id param to prevent duplicates\n",
    "            new_tweets = api.user_timeline(user_id = user_id,count=200,max_id=oldest)\n",
    "\n",
    "            #save most recent tweets\n",
    "            alltweets.extend(new_tweets)\n",
    "\n",
    "            #update the id of the oldest tweet less one\n",
    "            oldest = alltweets[-1].id - 1\n",
    "\n",
    "            print (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "        \n",
    "    with open(tweets_location + user_id + '.json', 'a') as f:\n",
    "        for tweet in alltweets:\n",
    "            f.write(json.dumps(tweet._json) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the actually calling of the gathering function\n",
    "#### Needs to be rerun when we hit a rate limit (but doesn't rerun same IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/526 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 842554842421846015\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 829453799207104511\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 816343380867293183\n",
      "...604 tweets downloaded so far\n",
      "getting tweets before 813499617052532735\n",
      "...604 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|████████▉ | 472/526 [00:04<00:00, 105.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 839900219605204994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets downloaded so far\n",
      "getting tweets before 504291042267791359\n",
      "...598 tweets downloaded so far\n",
      "getting tweets before 460776013648367615\n",
      "...797 tweets downloaded so far\n",
      "getting tweets before 423134143094870016\n",
      "...996 tweets downloaded so far\n",
      "getting tweets before 378206411051655167\n",
      "...1196 tweets downloaded so far\n",
      "getting tweets before 326453750166331393\n",
      "...1362 tweets downloaded so far\n",
      "getting tweets before 292002090283319295\n",
      "...1362 tweets downloaded so far\n",
      "getting tweets before 543415574639165439\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 458953764779466752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      " 90%|████████▉ | 472/526 [00:17<00:02, 26.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...600 tweets downloaded so far\n",
      "getting tweets before 373896059774201855\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 301471657275564032\n",
      "...823 tweets downloaded so far\n",
      "getting tweets before 289019147944345599\n",
      "...823 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 474/526 [00:19<01:59,  2.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 839920348091006978\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 819306645331312640\n",
      "...418 tweets downloaded so far\n",
      "getting tweets before 816347277665140735\n",
      "...418 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 475/526 [00:22<01:59,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 837799762762022911\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 827389061417439232\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 819235318876557311\n",
      "...638 tweets downloaded so far\n",
      "getting tweets before 816680663504080896\n",
      "...638 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 476/526 [00:25<02:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 846791503112495104\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 839195449995087871\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 826857817583865856\n",
      "...720 tweets downloaded so far\n",
      "getting tweets before 816374604885151744\n",
      "...720 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 477/526 [00:31<02:52,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 827524274093178885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 478/526 [00:32<02:20,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...326 tweets downloaded so far\n",
      "getting tweets before 816434214392524799\n",
      "...326 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 479/526 [00:33<01:46,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816332285591044096\n",
      "...124 tweets downloaded so far\n",
      "getting tweets before 843922424542482431\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 831362295259394047\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 822473193864753155\n",
      "...687 tweets downloaded so far\n",
      "getting tweets before 817062778028625919\n",
      "...687 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 481/526 [00:39<01:45,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816317963469025279\n",
      "...99 tweets downloaded so far\n",
      "getting tweets before 817099078702088193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 482/526 [00:41<01:42,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...88 tweets downloaded so far\n",
      "getting tweets before 819556791596052479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 483/526 [00:43<01:35,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...201 tweets downloaded so far\n",
      "getting tweets before 819227072937816063\n",
      "...201 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 484/526 [00:44<01:18,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816416677541904384\n",
      "...181 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 485/526 [00:45<01:05,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 829004915821383683\n",
      "...84 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 486/526 [00:46<00:54,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 820796192992935935\n",
      "...105 tweets downloaded so far\n",
      "getting tweets before 836702114340560896\n",
      "...311 tweets downloaded so far\n",
      "getting tweets before 816335725092360191\n",
      "...311 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 487/526 [00:47<00:56,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 821836214257012738\n",
      "...211 tweets downloaded so far\n",
      "getting tweets before 818721454212714495\n",
      "...211 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 488/526 [00:49<00:54,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 840269952502382592\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 826184847341322240\n",
      "...498 tweets downloaded so far\n",
      "getting tweets before 816672073871458303\n",
      "...498 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 489/526 [00:51<01:05,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 819190129667571712\n",
      "...217 tweets downloaded so far\n",
      "getting tweets before 816378469047095295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 490/526 [00:53<01:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...217 tweets downloaded so far\n",
      "getting tweets before 822190985522401279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 491/526 [00:56<01:16,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...241 tweets downloaded so far\n",
      "getting tweets before 816277504751206399\n",
      "...241 tweets downloaded so far\n",
      "getting tweets before 817494052354584575\n",
      "...186 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 492/526 [00:57<01:02,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 819925966038429696\n",
      "...228 tweets downloaded so far\n",
      "getting tweets before 816305653471969280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 493/526 [00:59<00:58,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...228 tweets downloaded so far\n",
      "getting tweets before 840272528446754815\n",
      "...382 tweets downloaded so far\n",
      "getting tweets before 816724999151161343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 494/526 [01:02<01:07,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...382 tweets downloaded so far\n",
      "getting tweets before 834049988288188415\n",
      "...337 tweets downloaded so far\n",
      "getting tweets before 816296203243622400\n",
      "...337 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 496/526 [01:04<00:47,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816454949257314303\n",
      "...69 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 498/526 [01:05<00:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 844204534381592575\n",
      "...48 tweets downloaded so far\n",
      "getting tweets before 828981050705641471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 499/526 [01:06<00:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...129 tweets downloaded so far\n",
      "getting tweets before 836307873152008192\n",
      "...215 tweets downloaded so far\n",
      "getting tweets before 827283497228259327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 500/526 [01:09<00:43,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...215 tweets downloaded so far\n",
      "getting tweets before 849332235559948288\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 844209044097290239\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 837678514488893440\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 833522304734871551\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 826229788738277379\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 819008303686676480\n",
      "...1277 tweets downloaded so far\n",
      "getting tweets before 816121037154906111\n",
      "...1277 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 501/526 [01:16<01:21,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 828954638925885440\n",
      "...260 tweets downloaded so far\n",
      "getting tweets before 816714397825564672\n",
      "...260 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 502/526 [01:18<01:07,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816362470843551743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 503/526 [01:19<00:51,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...157 tweets downloaded so far\n",
      "getting tweets before 826169502161264639\n",
      "...243 tweets downloaded so far\n",
      "getting tweets before 816301938010652672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 504/526 [01:22<00:56,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...243 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 505/526 [01:24<00:48,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 817178608955518975\n",
      "...146 tweets downloaded so far\n",
      "getting tweets before 837369473778737151\n",
      "...326 tweets downloaded so far\n",
      "getting tweets before 819388164259381247\n",
      "...326 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 506/526 [01:26<00:47,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 836965701638320130\n",
      "...367 tweets downloaded so far\n",
      "getting tweets before 816299921166974976\n",
      "...367 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 507/526 [01:28<00:41,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 836763599288823808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 508/526 [01:29<00:34,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...237 tweets downloaded so far\n",
      "getting tweets before 819410838717140996\n",
      "...237 tweets downloaded so far\n",
      "getting tweets before 846538811337265151\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 836653416491397119\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 824422858524856320\n",
      "...694 tweets downloaded so far\n",
      "getting tweets before 816722082239279103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 509/526 [01:33<00:40,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...694 tweets downloaded so far\n",
      "getting tweets before 817459756369481728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 510/526 [01:35<00:37,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...114 tweets downloaded so far\n",
      "getting tweets before 849302818498514943\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 844643093186052107\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 839496122624315391\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 833029082011074559\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 825451823599386624\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 817461000702197760\n",
      "...1211 tweets downloaded so far\n",
      "getting tweets before 817098872531144703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 511/526 [01:41<00:53,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1211 tweets downloaded so far\n",
      "getting tweets before 818548732044132355\n",
      "...213 tweets downloaded so far\n",
      "getting tweets before 816370141143384063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 512/526 [01:43<00:42,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...213 tweets downloaded so far\n",
      "getting tweets before 830450704401694720\n",
      "...273 tweets downloaded so far\n",
      "getting tweets before 816668131653545984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 513/526 [01:50<00:53,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...273 tweets downloaded so far\n",
      "getting tweets before 829391087018057727\n",
      "...268 tweets downloaded so far\n",
      "getting tweets before 816381373732659205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 514/526 [02:10<01:45,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...268 tweets downloaded so far\n",
      "getting tweets before 817454285696958463\n",
      "...398 tweets downloaded so far\n",
      "getting tweets before 675414820460564479\n",
      "...597 tweets downloaded so far\n",
      "getting tweets before 595283508366540799\n",
      "...797 tweets downloaded so far\n",
      "getting tweets before 514528039481671679\n",
      "...997 tweets downloaded so far\n",
      "getting tweets before 417745093190103040\n",
      "...1197 tweets downloaded so far\n",
      "getting tweets before 325340561974374399\n",
      "...1397 tweets downloaded so far\n",
      "getting tweets before 236565465831452671\n",
      "...1597 tweets downloaded so far\n",
      "getting tweets before 73477783103340544\n",
      "...1797 tweets downloaded so far\n",
      "getting tweets before 6272644141\n",
      "...1858 tweets downloaded so far\n",
      "getting tweets before 1870428520\n",
      "...1858 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 515/526 [02:21<01:46,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 844684734420701183\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 822261295311417345\n",
      "...418 tweets downloaded so far\n",
      "getting tweets before 819992373354631167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 516/526 [02:25<01:17,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...418 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 517/526 [02:26<00:51,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816793313810518015\n",
      "...129 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 518/526 [02:26<00:32,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 818878415927410688\n",
      "...3 tweets downloaded so far\n",
      "getting tweets before 817400853674004480\n",
      "...208 tweets downloaded so far\n",
      "getting tweets before 816333100405968895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 519/526 [02:28<00:24,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...208 tweets downloaded so far\n",
      "getting tweets before 840213006571229183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 520/526 [02:29<00:17,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...11 tweets downloaded so far\n",
      "getting tweets before 839206373388877823\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 820001473723502597\n",
      "...444 tweets downloaded so far\n",
      "getting tweets before 816424932993302527\n",
      "...444 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 521/526 [02:32<00:14,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 827238540937412608\n",
      "...259 tweets downloaded so far\n",
      "getting tweets before 818890976236290049\n",
      "...259 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 522/526 [02:34<00:10,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 853003746241953791\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 849756342206189567\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 847572067369091071\n",
      "...799 tweets downloaded so far\n",
      "getting tweets before 845411092398428159\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 844295903594860544\n",
      "...1198 tweets downloaded so far\n",
      "getting tweets before 842390817436254209\n",
      "...1398 tweets downloaded so far\n",
      "getting tweets before 839963447668400131\n",
      "...1598 tweets downloaded so far\n",
      "getting tweets before 837754277594439679\n",
      "...1798 tweets downloaded so far\n",
      "getting tweets before 834933729860583424\n",
      "...1998 tweets downloaded so far\n",
      "getting tweets before 833371514586042372\n",
      "...2197 tweets downloaded so far\n",
      "getting tweets before 829830320874622975\n",
      "...2397 tweets downloaded so far\n",
      "getting tweets before 826154007542460415\n",
      "...2595 tweets downloaded so far\n",
      "getting tweets before 821124209082384384\n",
      "...2703 tweets downloaded so far\n",
      "getting tweets before 816311625540075521\n",
      "...2703 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 523/526 [03:13<00:39, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 831563849484607487\n",
      "...317 tweets downloaded so far\n",
      "getting tweets before 816275664596766719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 524/526 [03:16<00:20, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...317 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 525/526 [03:17<00:07,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 816816691774529535\n",
      "...67 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 526/526 [03:19<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 829803754715283457\n",
      "...127 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for guid in tqdm(good_user_ids):\n",
    "    # if the file exists, we've already done this one\n",
    "    # this is not the smoothest way to do this, but oh well\n",
    "    # http://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists-using-python?page=1&tab=votes#tab-top\n",
    "    if os.path.isfile(tweets_location + guid + '.json') == False: \n",
    "        get_all_tweets(guid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Debugging Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking that the numbers match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526 526 True\n"
     ]
    }
   ],
   "source": [
    "located = 0\n",
    "for guid in good_user_ids:\n",
    "    if os.path.isfile(tweets_location + guid + '.json'):\n",
    "        located += 1\n",
    "print(located, len(good_user_ids), located == len(good_user_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
